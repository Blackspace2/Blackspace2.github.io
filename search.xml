<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>B样条曲线简介及其python实现</title>
    <url>/2025/01/08/B%E6%A0%B7%E6%9D%A1%E6%9B%B2%E7%BA%BF/</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><span id="more"></span>
<h2 id="b样条曲线的计算公式">1. B样条曲线的计算公式</h2>
<p>B 样条曲线 <span class="math inline">\(P(u)\)</span>
可以表示为控制点和基函数的加权和： <span class="math display">\[
P(u)=\sum_{i=0}^{n} {p_i B_{i,k}(u)} \ ,u\in \left[ u_{k-1}, u_{k+1}
\right]
\tag{1}
\]</span></p>
<h2 id="符号解释">2. 符号解释</h2>
<h3 id="pu">2.1 <span class="math inline">\(P(u)\)</span></h3>
<p>B 样条曲线上的点，也是我们所要求的结果。</p>
<h3 id="p_i">2.2 <span class="math inline">\(p_i\)</span></h3>
<p>控制点， <span class="math inline">\(i=0,1,2,..,n\)</span>，一共有
<span class="math inline">\(n+1\)</span> 个。</p>
<h3 id="b_ik">2.3 <span class="math inline">\(B_{i,k}\)</span></h3>
<p>基函数</p>
<h3 id="u">2.4 <span class="math inline">\(u\)</span> <span
id="2.4"></span></h3>
<p>相当于自变量，有效区间为 <span class="math inline">\(\left[ u_{k-1},
u_{k+1} \right]\)</span>。</p>
<h3 id="k">2.5 <span class="math inline">\(k\)</span></h3>
<p>B
样条曲线的<strong>次数</strong>，这里要注意次数和阶数的区别和联系：次数
= 阶数 - 1。</p>
<p>对于 B 样条的次数 <span
class="math inline">\(k\)</span>，必须满足：<span id="(2)"></span> <span
class="math display">\[k = m - n - 1 \tag{2}\]</span> 其中 <span
class="math inline">\(m\)</span><span id="m"></span> 是 <strong>节点
(knots)</strong> 将 B 样条曲线划分的段数，<span
class="math inline">\(n\)</span> 为控制点的个数减一。</p>
<p>上面说的节点就是划分 B
样条的比例，由节点组成的一组向量就成为节点矢量，例如
<code>[0, 0.2, 0.4, 0.6, 0.8, 1]</code>。不同的节点矢量进而产生了不同的
B 样条种类，例如均匀 B 样条、准均匀 B 样条、分段 B 样条以及非均匀 B
样条等等。</p>
<h2 id="基函数的计算">3. 基函数的计算</h2>
<p>de Boor-Cox递归方法<br />
<span class="math display">\[
B_{i,k}(u)=\frac{u-u_i}{u_{i+1}-u_i}B_{i,k-1}(u)+\frac{u_{i+k}-u}{u_{i+k}-u_{i+1}}B_{i+1,k-1}(u)
\tag{3}
\]</span></p>
<p>这里需要给出说明，不带下标的 <span class="math inline">\(u\)</span>
指的是 <a href="#2.4">2.4</a> 中的 <span
class="math inline">\(u\)</span>，而带下标则指的是节点矢量。</p>
<p>在代码实现中，我们规定 <span
class="math inline">\(\frac{0}{0}=0\)</span>。</p>
<h2 id="节点矢量-knots-的计算">4. 节点矢量 (knots) 的计算</h2>
<p>节点矢量的取值可以是在 0 到 1
之间，也可以是其他范围，但是在代码是实现的时候一定要注意前后保持一致。<br />
本文使用节点矢量取值为 0 到 1，这样也可以表示比例嘛。</p>
<p>这里需要注意节矢量的长度，也就是 <span
class="math inline">\(m\)</span>，通过式 <a href="#(2)">(2)</a>
可知，<span class="math inline">\(m=k+n+1\)</span>。</p>
<h3 id="均匀节点-uniform-node">4.1 均匀节点 (uniform node)</h3>
<p>显然，节点的分布是均匀的，故从 0 到
1按照节点矢量的长度均匀划分即可。<br />
（因为要将曲线划分为 <a href="#m">m</a> 段，当然需要 m+1个点）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">uniform_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> np.linspace(<span class="number">0</span>, <span class="number">1</span>, n + k + <span class="number">2</span>)  <span class="comment"># m = n + k + 1</span></span><br></pre></td></tr></table></figure>
<p>均匀 B 样条曲线不一定过首尾控制点，并且在图像上是闭合的</p>
<h3 id="准均匀节点-quasi-uniform-node">4.2 准均匀节点 (quasi uniform
node)</h3>
<p>准均匀节点可以目的在于对曲线的端点进行行为控制，通过设计节点矢量，使得生成的
B 样条曲线经过首尾控制点。<br />
<span class="math inline">\(k\)</span>
次准均匀节点矢量中，两端节点具有重复度 <span
class="math inline">\(k+1\)</span>，所有内节点呈现均匀分布。<br />
在代码实现中，我们可以让节点矢量首尾分别为 <span
class="math inline">\(k\)</span> 个 0 和 1，然后中间 <span
class="math inline">\(n-k+2\)</span> 为 0 到 1 的均匀分布就行了，即
<span class="math display">\[ \nonumber
\left[ \begin{matrix}
\underset{k}{\underbrace{0,0,...,0}},\
\underset{n-k+2}{\underbrace{0,...,1}},\
\underset{k}{\underbrace{1,1,...,1}}\\
\end{matrix} \right]
\]</span></p>
<figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">quasi_uniform_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line">    mid = np.linspace(<span class="number">0</span>, <span class="number">1</span>, n - k + <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> np.r_[np.zeros(k), mid, np.ones(k)]  <span class="comment"># 拼接</span></span><br></pre></td></tr></table></figure>
<h3 id="分段节点-piecewise-node">4.3 分段节点 (piecewise node)</h3>
<p>基于该节点矢量的 B 样样条曲线又称为分段 Bezier
曲线，是一组顺序首尾相接且同为 <span class="math inline">\(k\)</span>
次的 Bezier 曲线。<br />
<span class="math inline">\(k\)</span>
次的分段节点矢量中，首末端节点重复度依旧为 <span
class="math inline">\(k+1\)</span>，内节点重复度为 <span
class="math inline">\(k\)</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">piecewise_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## restricted condition</span></span><br><span class="line">    <span class="keyword">assert</span> (n - k) % k == <span class="number">0</span>, <span class="string">&quot;input is valid.&quot;</span></span><br><span class="line"></span><br><span class="line">    tmp = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">int</span>((n - k) / k + <span class="number">2</span>))</span><br><span class="line">    mid = np.r_[tmp[<span class="number">0</span>], np.repeat(tmp[<span class="number">1</span>:-<span class="number">1</span>], k), tmp[-<span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">return</span> np.r_[np.zeros(k), mid, np.ones(k)]</span><br></pre></td></tr></table></figure>
<p>需要注意 <span class="math inline">\(n-k\)</span> 必须是 <span
class="math inline">\(k\)</span> 的整数倍，否则不能生成曲线。</p>
<h3 id="非均匀节点-non-uniform-node">4.4 非均匀节点 (non-uniform
node)</h3>
<p>Hartley-Judd 算法 首尾重合度为 <span
class="math inline">\(k+1\)</span>，内节点定义为：</p>
<p><span class="math display">\[
\begin{cases}
t_k=0\\
t_i=\sum_{j=k+1}^i{\bigl( t_j-t_{j-1} \bigr)} \\
t_{n+1}=1\\
\end{cases}
\tag{4}
\]</span> <span class="math display">\[
t_i-t_{i-1}=\frac{\sum_{j=i-k}^{i-1}{l_j}}{\sum_{i=k+1}^{n+1}{\sum_{j=i-k}^{i-1}{l_j}}}
\tag{5}
\]</span></p>
<figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">non_uniform_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    l = np.sqrt(np.<span class="built_in">sum</span>(np.diff(control_points, axis=<span class="number">0</span>) ** <span class="number">2</span>, axis=<span class="number">1</span>))</span><br><span class="line">    ll = l[<span class="number">0</span> : <span class="built_in">len</span>(l) - <span class="number">1</span>] + l[<span class="number">1</span>::]</span><br><span class="line">    L = np.<span class="built_in">sum</span>(ll)</span><br><span class="line"></span><br><span class="line">    mid_size = n - k</span><br><span class="line">    mid = np.zeros(mid_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(mid_size):</span><br><span class="line">        mid[i] = np.<span class="built_in">sum</span>(ll[<span class="number">0</span> : i + <span class="number">1</span>]) / L</span><br><span class="line"></span><br><span class="line">    knots = np.r_[np.zeros(k + <span class="number">1</span>), mid, np.ones(k + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> knots</span><br></pre></td></tr></table></figure>
<h2 id="python-实现">5. python 实现</h2>
<figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">uniform_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.linspace(<span class="number">0</span>, <span class="number">1</span>, n + k + <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quasi_uniform_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line">    mid = np.linspace(<span class="number">0</span>, <span class="number">1</span>, n - k + <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.r_[np.zeros(k), mid, np.ones(k)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">piecewise_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## restricted condition</span></span><br><span class="line">    <span class="keyword">assert</span> (n - k) % k == <span class="number">0</span>, <span class="string">&quot;input is valid.&quot;</span></span><br><span class="line"></span><br><span class="line">    tmp = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">int</span>((n - k) / k + <span class="number">2</span>))</span><br><span class="line">    mid = np.r_[tmp[<span class="number">0</span>], np.repeat(tmp[<span class="number">1</span>:-<span class="number">1</span>], k), tmp[-<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.r_[np.zeros(k), mid, np.ones(k)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">non_uniform_node</span>(<span class="params">control_points, k=<span class="number">3</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Hartley-Judd algorithem</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num, _ = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    l = np.sqrt(np.<span class="built_in">sum</span>(np.diff(control_points, axis=<span class="number">0</span>) ** <span class="number">2</span>, axis=<span class="number">1</span>))</span><br><span class="line">    ll = l[<span class="number">0</span> : <span class="built_in">len</span>(l) - <span class="number">1</span>] + l[<span class="number">1</span>::]</span><br><span class="line">    L = np.<span class="built_in">sum</span>(ll)</span><br><span class="line"></span><br><span class="line">    mid_size = n - k</span><br><span class="line">    mid = np.zeros(mid_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(mid_size):</span><br><span class="line">        mid[i] = np.<span class="built_in">sum</span>(ll[<span class="number">0</span> : i + <span class="number">1</span>]) / L</span><br><span class="line"></span><br><span class="line">    knots = np.r_[np.zeros(k + <span class="number">1</span>), mid, np.ones(k + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> knots</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_B</span>(<span class="params">i, k, knots, u</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    de Boor-Cox recursion</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        i (int): ith point idx</span></span><br><span class="line"><span class="string">        k (int): degree of b-spline , equal to ord - 1</span></span><br><span class="line"><span class="string">        knots (ndarray): 1 dim</span></span><br><span class="line"><span class="string">        u : independent variable</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        B: B_&#123;i,k&#125;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">1</span>:</span><br><span class="line">        B = <span class="number">1</span> <span class="keyword">if</span> knots[i] &lt;= u &lt;= knots[i + <span class="number">1</span>] <span class="keyword">else</span> <span class="number">0</span>  <span class="comment">##</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        coef1 = coef2 = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> knots[i + k - <span class="number">1</span>] - knots[i] != <span class="number">0</span>:</span><br><span class="line">            coef1 = (u - knots[i]) / (knots[i + k - <span class="number">1</span>] - knots[i])</span><br><span class="line">        <span class="keyword">if</span> knots[i + k] - knots[i + <span class="number">1</span>] != <span class="number">0</span>:</span><br><span class="line">            coef2 = (knots[i + k] - u) / (knots[i + k] - knots[i + <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        B = coef1 * cal_B(i, k - <span class="number">1</span>, knots, u) + coef2 * cal_B(i + <span class="number">1</span>, k - <span class="number">1</span>, knots, u)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> B</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_curve</span>(<span class="params">control_points, knots, t</span>):</span><br><span class="line"></span><br><span class="line">    num, dims = control_points.shape</span><br><span class="line">    n = num - <span class="number">1</span></span><br><span class="line">    k = <span class="built_in">len</span>(knots) - n - <span class="number">1</span>  <span class="comment"># degree of b-spline</span></span><br><span class="line"></span><br><span class="line">    N = <span class="built_in">len</span>(t)</span><br><span class="line">    P = np.zeros((N, dims))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        u = t[idx]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num):</span><br><span class="line">            P[idx, :] += control_points[i, :] * cal_B(i, k, knots, u)</span><br><span class="line">    <span class="keyword">return</span> P</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 体验 https://superjerryshen.github.io/b-spline-demos/##/uniform-b-spline-of-order-3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">    control_points = np.array([[<span class="number">50</span>, <span class="number">50</span>], [<span class="number">100</span>, <span class="number">300</span>], [<span class="number">300</span>, <span class="number">100</span>], [<span class="number">380</span>, <span class="number">200</span>], [<span class="number">400</span>, <span class="number">600</span>], [<span class="number">500</span>, <span class="number">400</span>], [<span class="number">300</span>, <span class="number">600</span>]])</span><br><span class="line">    </span><br><span class="line">    N = <span class="number">500</span></span><br><span class="line">    t = np.linspace(<span class="number">0.0</span>, <span class="number">1.0</span>, N)</span><br><span class="line"></span><br><span class="line">    uniform_knots = uniform_node(control_points)</span><br><span class="line">    quasi_knots = quasi_uniform_node(control_points)</span><br><span class="line">    piecewise_knots = piecewise_node(control_points)</span><br><span class="line">    non_knots = non_uniform_node(control_points)</span><br><span class="line"></span><br><span class="line">    P_uniform = cal_curve(control_points, uniform_knots, t)</span><br><span class="line">    P_quasi = cal_curve(control_points, quasi_knots, t)</span><br><span class="line">    P_piecewise = cal_curve(control_points, piecewise_knots, t)</span><br><span class="line">    P_non = cal_curve(control_points, non_knots, t)</span><br><span class="line"></span><br><span class="line">    fig, axs = plt.subplots(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## 均匀 会闭合</span></span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">0</span>].scatter(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, facecolors=<span class="string">&quot;none&quot;</span>, label=<span class="string">&quot;control points&quot;</span>)</span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">0</span>].plot(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, linewidth=<span class="number">0.2</span>)</span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">0</span>].plot(P_uniform[:, <span class="number">0</span>], P_uniform[:, <span class="number">1</span>], color=<span class="string">&quot;C3&quot;</span>, label=<span class="string">&quot;uniform&quot;</span>)</span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">0</span>].legend()</span><br><span class="line"></span><br><span class="line">    <span class="comment">## 准均匀</span></span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">1</span>].scatter(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, facecolors=<span class="string">&quot;none&quot;</span>, label=<span class="string">&quot;control points&quot;</span>)</span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">1</span>].plot(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, linewidth=<span class="number">0.2</span>)</span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">1</span>].plot(P_quasi[:, <span class="number">0</span>], P_quasi[:, <span class="number">1</span>], color=<span class="string">&quot;C3&quot;</span>, label=<span class="string">&quot;quasi&quot;</span>)</span><br><span class="line">    axs[<span class="number">0</span>, <span class="number">1</span>].legend()</span><br><span class="line"></span><br><span class="line">    <span class="comment">## 分段</span></span><br><span class="line">    axs[<span class="number">1</span>, <span class="number">0</span>].scatter(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, facecolors=<span class="string">&quot;none&quot;</span>, label=<span class="string">&quot;control points&quot;</span>)</span><br><span class="line">    axs[<span class="number">1</span>, <span class="number">0</span>].plot(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, linewidth=<span class="number">0.2</span>)</span><br><span class="line">    axs[<span class="number">1</span>, <span class="number">0</span>].plot(P_piecewise[:, <span class="number">0</span>], P_piecewise[:, <span class="number">1</span>], color=<span class="string">&quot;C3&quot;</span>, label=<span class="string">&quot;piecewise&quot;</span>)</span><br><span class="line">    axs[<span class="number">1</span>, <span class="number">0</span>].legend()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## HJ 非均匀</span></span><br><span class="line">    axs[<span class="number">1</span>,<span class="number">1</span>].scatter(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, facecolors=<span class="string">&quot;none&quot;</span>, label=<span class="string">&quot;control points&quot;</span>)</span><br><span class="line">    axs[<span class="number">1</span>,<span class="number">1</span>].plot(control_points[:, <span class="number">0</span>], control_points[:, <span class="number">1</span>], color=<span class="string">&quot;C0&quot;</span>, linewidth=<span class="number">0.2</span>)</span><br><span class="line">    axs[<span class="number">1</span>,<span class="number">1</span>].plot(P_non[:, <span class="number">0</span>], P_non[:, <span class="number">1</span>], color=<span class="string">&quot;C3&quot;</span>, label=<span class="string">&quot;non uniform&quot;</span>)</span><br><span class="line">    axs[<span class="number">1</span>,<span class="number">1</span>].legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>效果：<br />
<img src="BSpline.png" alt="BSpline" /></p>
<p>todo：<br />
很诡异的一点，在 <code>cal_curve</code> 函数中计算 <span
class="math inline">\(k\)</span> 的时候，满足 <span
class="math inline">\(k=m-n-1\)</span>
的时候，后三种样条曲线都不经过首尾控制点，这是不符合预期的，但是用 <span
class="math inline">\(k = (m+1) - n - 1\)</span>
的时候，却和正常预期的结果一样，不知道是哪里出问题了。<br />
有空了再来填补空缺</p>
<h2 id="参考">6. 参考</h2>
<p><strong>[1]</strong> <a
href="https://b23.tv/e93CqZR">计算机图形学-中国农大-赵明-B站
8.5.1~8.6.2</a><br />
<strong>[2]</strong> <a
href="https://blog.csdn.net/deepsprings/article/details/107828889?spm=1001.2014.3001.5506">详解样条曲线-CSDN</a><br />
<strong>[3]</strong> <a
href="https://zhuanlan.zhihu.com/p/686518292">B样条曲线和Nurbs曲线
图文并茂的理解节点和节点区间-知乎</a><br />
<strong>[4]</strong>《计算几何算法与实现》—— 孔令德</p>
]]></content>
      <categories>
        <category>计算机图形学</category>
        <category>B样条</category>
      </categories>
      <tags>
        <tag>B样条</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 中的 markdown 语法</title>
    <url>/2025/01/07/Hexo%E4%B8%AD%E7%9A%84md%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><span id="more"></span>
<h2 id="页内跳转">1. 页内跳转</h2>
<p>跳转到地方后面加上
<code>&lt;span id="jump"&gt;&lt;/span&gt;</code><br />
需要跳转的地方 <code>[跳转到](#jump)</code></p>
<h2 id="博客嵌入图片">2. 博客嵌入图片</h2>
<p>在 Hexo 的 <code>_config.yml</code> 文件下设置：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">marked:</span></span><br><span class="line">  <span class="attr">prependRoot:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">postAsset:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>此后当新建 <code>.md</code>
文件时，会在同级目录下自动生成一个同名文件夹，里面课以用于存放附件（如图片等）。<br />
此时图片引用语法： <code>![文本](图片名字)</code></p>
<h2 id="html-插入图片">3. html 插入图片</h2>
<p><code>&lt;img src="图片路径" width="像素或者缩放百分比" height="像素或者缩放百分比"/&gt;</code></p>
<h2 id="数学公式以及编号问题">4. 数学公式以及编号问题</h2>
<p>渲染引擎：MathJax<br />
插件：hexo-renderer-pandoc<br />
参数（位于<code>_config.next.yml</code>）：<code>mathjax.tags = all</code></p>
<p>写行间公式的时候，两个 <code>$$</code>
一定要分别紧靠开头和结尾，并且中间不能有空行，否则在网页上会看见开头和结尾的两个
<code>$$</code> 符号（虽然公式可以正常渲染出来）。</p>
<p>在上述环境下，hexo 会自动给每个公式进行编号，当然也可以用
<code>\tag&#123;&#125;</code> 自己设置编号。如果使用 <code>\tag&#123;&#125;</code>
自定义编号，那么 hexo
依然会跳过这个公式并且对后面的公式进行自动编号。<br />
当公式不需要编号的时候，可以用 <code>\nonumber</code> 或
<code>\notag</code> 来标记；此外，也可以使用 带 <code>*</code> 的
<code>equation</code> 环境来取消对公式的编号。</p>
<p>对于公式引用，Next 官方文档中提到可以用 <code>\label&#123;&#125;</code>
和对应的 <code>\eqref&#123;&#125;</code> 来进行相应的公式引用。</p>
<p>参考：<br />
[1] <a
href="https://theme-next.js.org/docs/third-party-services/math-equations">Next
官方文档</a><br />
[2] <a
href="https://docs.mathjax.org/en/latest/input/tex/eqnumbers.html">MathJax
公式编号说明</a></p>
]]></content>
  </entry>
  <entry>
    <title>常用矩阵计算</title>
    <url>/2025/01/15/%E5%B8%B8%E7%94%A8%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><span id="more"></span>
<h2 id="符号约定">1. 符号约定</h2>
<p>正常小写字母表示标量；<br />
加粗小写字母表示向量，无特殊说明时通常为<strong>列向量</strong>；<br />
大写字母表示矩阵；</p>
<h2 id="求导">2. 求导</h2>
<p>矩阵求导中的 <strong>分子布局</strong> 和 <strong>分母布局</strong>
是两种不同的约定方式，它们的主要区别在于约定导数的结果的维度和排列方式，二者均正确，但需要保障在同一环境下只能使用一种布局方式。<br />
区分是分子布局还是分母布局，可以看求导结果的第一个维度是等于分子的第一个维度还是分母的第一个维度。<br />
可以注意到分子布局和分母布局的结果互为转置。</p>
<div class="tabs" id="first-unique-name"><ul class="nav-tabs"><li class="tab active"><a href="#first-unique-name-1">分母布局</a></li><li class="tab"><a href="#first-unique-name-2">分子布局</a></li></ul><div class="tab-content"><div class="tab-pane active" id="first-unique-name-1"><p><span class="math display">\[\begin{equation*}
\begin{aligned}
\frac{\partial \boldsymbol{A}\boldsymbol{x}}{\partial
\boldsymbol{x}}&amp; =\boldsymbol{A}^T \\
\frac{\partial \boldsymbol{\alpha}^{T}\boldsymbol{x}}{\partial
\boldsymbol{x}}&amp; =\frac{\partial
\boldsymbol{x}^{T}\boldsymbol{\alpha}}{\partial
\boldsymbol{x}}=\boldsymbol{\alpha}\\
\frac{\partial\boldsymbol{y}^{T}\boldsymbol{Ax}}{\partial
\boldsymbol{A}} &amp;= \boldsymbol{y}\boldsymbol{x}^{T}  \\
\frac{\partial
\boldsymbol{x}^T\boldsymbol{A}\boldsymbol{x}}{\partial\boldsymbol{x}}&amp;=\boldsymbol{Ax}+\boldsymbol{A}^T\boldsymbol{x}\
\xlongequal{\text{if A is symmetric}} 2\boldsymbol{Ax}  \\
\end{aligned}
\end{equation*}
\]</span></p></div><div class="tab-pane" id="first-unique-name-2"><p><span class="math display">\[
\begin{equation*}
\begin{aligned}
\frac{\partial \boldsymbol{A}\boldsymbol{x}}{\partial
\boldsymbol{x}}&amp; =\boldsymbol{A}  \\
\frac{\partial \boldsymbol{\alpha}^{T}\boldsymbol{x}}{\partial
\boldsymbol{x}}&amp; =\frac{\partial
\boldsymbol{x}^{T}\boldsymbol{\alpha}}{\partial
\boldsymbol{x}}=\boldsymbol{\alpha}^T  \\
\frac{\partial\boldsymbol{y}^{T}\boldsymbol{Ax}}{\partial
\boldsymbol{A}} &amp;= \boldsymbol{y}^{T}\boldsymbol{x} \\
\frac{\partial
\boldsymbol{x}^T\boldsymbol{A}\boldsymbol{x}}{\partial\boldsymbol{x}}&amp;=\boldsymbol{x}^T\boldsymbol{A}^T+\boldsymbol{x}^T\boldsymbol{A}\
\xlongequal{\text{if A is symmetric}} 2\boldsymbol{x}^T \boldsymbol{A}
\\
\end{aligned}
\end{equation*}
\]</span></p></div></div></div>
]]></content>
      <categories>
        <category>数学</category>
        <category>矩阵计算</category>
      </categories>
      <tags>
        <tag>矩阵计算</tag>
      </tags>
  </entry>
  <entry>
    <title>git 命令思维导图</title>
    <url>/2025/01/17/git-%E5%91%BD%E4%BB%A4%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><span id="more"></span>
<figure>
<img src="git.jpg" alt="git 命令思维导图" />
<figcaption aria-hidden="true">git 命令思维导图</figcaption>
</figure>
<p>来源：<a
href="https://github.com/toypipi/graph_bed/blob/master/image/20200810/git%E5%91%BD%E4%BB%A4%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.jpg">github</a></p>
]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>非线性最小二乘</title>
    <url>/2025/01/15/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98/</url>
    <content><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><span id="more"></span>
<h2 id="前言">1. 前言</h2>
<p>先考虑一个最简单的最小二乘问题： <span class="math display">\[
\underset{x}{min} \frac{1}{2} \|f(\boldsymbol{x}) \|_{2}^{2}
\]</span> 这里自变量 <span class="math inline">\(\boldsymbol{x} \in
\mathbb{R}^n\)</span> ， <span class="math inline">\(f\)</span>
是任意一个非线性函数，假设他有 <span class="math inline">\(m\)</span>
维： <span class="math inline">\(f(\boldsymbol{x}) \in
\mathbb{R}^m\)</span> 。</p>
<p>考虑 <span class="math inline">\(f\)</span>
的形式基本有两种解决方法：解析法和迭代法。</p>
<h3 id="解析法">1.1 解析法</h3>
<p>当 <span class="math inline">\(f\)</span>
的数学形式比较简单的时候，或许问题可以直接用解析形式来求解。也就是让目标函数的导数为
0 ，然后求解 <span class="math inline">\(\boldsymbol{x}\)</span>
的最优值： <span class="math display">\[
\frac{\partial f}{\partial \boldsymbol{x}}=0 \nonumber
\]</span> 解上述方程即可得到目标函数导数为 0
的极值，它可能是极大值、极小值或者鞍点处的值，依次比较即可得到最小值。<br />
显然这种方法较为局限。</p>
<h3 id="迭代法">1.2 迭代法</h3>
<p>对于不易直接求导的目标函数，我们可以用迭代的方法来求极小值。根据给定的初值，不断地更新当前的优化变量，使得目标函数朝着下降的方向变化。具体步骤列写如下：</p>
<ol type="1">
<li>给定初值 <span class="math inline">\(\boldsymbol{x}_0\)</span>
；<br />
</li>
<li>对于第 <span class="math inline">\(k\)</span> 次迭代，寻找一个增量
<span class="math inline">\(\Delta \boldsymbol{x}_k\)</span>，使得 <span
class="math inline">\(\|f(\boldsymbol{x}_k + \Delta
\boldsymbol{x}_k)\|_{2}^{2}\)</span> 达到极小值；<br />
</li>
<li>如果 <span class="math inline">\(\Delta \boldsymbol{x}_k\)</span>
足够小，则停止；<br />
</li>
<li>否则，令 <span
class="math inline">\(\boldsymbol{x}_{k+1}=\boldsymbol{x}_k + \Delta
\boldsymbol{x}_k\)</span>，返回2。</li>
</ol>
<p>这样问题就转化为如何确定增量 <span class="math inline">\(\Delta
\boldsymbol{x}_k\)</span>，使上述过程收敛，通常有下面的几种方法。</p>
<h2 id="一阶和二阶梯度法最速下降法和牛顿法">2.
一阶和二阶梯度法（最速下降法和牛顿法）</h2>
<p>求解增量最直观的方法就是将 <strong>目标函数</strong> <span
id="梯度法"></span> 在 <span
class="math inline">\(\boldsymbol{x}\)</span> 进行泰勒展开： <span
class="math display">\[
\|f(\boldsymbol{x}+\Delta\boldsymbol{x})
\|_{2}^{2}=\|f(\boldsymbol{x})\|_{2}^{2}+\boldsymbol{J}(\boldsymbol{x})\Delta
\boldsymbol{x}+\frac{1}{2}\Delta \boldsymbol{x }^T \boldsymbol{H} \Delta
\boldsymbol{x}.
\]</span></p>
<p>这里 <span class="math inline">\(\boldsymbol{J}\)</span> 是 <span
class="math inline">\(\|f(\boldsymbol{x}) \|_{2}^{2}\)</span> 关于 <span
class="math inline">\(x\)</span> 的导数（雅可比矩阵），<span
class="math inline">\(\boldsymbol{H}\)</span>
则是二阶导数（黑塞矩阵）。我们可以选择保留泰勒展开的一阶或二阶项，对应的求解方法则为一阶梯度或二阶梯度法。</p>
<p>如果保留一阶梯度，那么增量的方向为： <span class="math display">\[
\Delta \boldsymbol{x}^{*}=-\boldsymbol{J}^T(\boldsymbol{x})
\]</span> 这里的转置是为了满足矩阵乘法的维度匹配。<br />
它的直观意义非常简单，只要我们沿着反向梯度方向前进即可。当然，我们还需要该方向上取一个步长
λ，求得最快的下降方式。这种方法被称为<strong>最速下降法</strong>。</p>
<p>如果保留二阶梯度，那么增量的解为： <span
class="math display">\[\label{二阶梯度法}
\boldsymbol{H} \Delta \boldsymbol{x}^{*}= - \boldsymbol{J}^T
\]</span> 该方法称又为<strong>牛顿法</strong>。</p>
<h3 id="小结">2.1 小结</h3>
<p>我们看到，一阶和二阶梯度法都十分直观，只要把函数在迭代点附近进行泰勒展开，并针对更新量作最小化即可。由于泰勒展开之后函数变成了多项式，所以求解增量时只需解线性方程即可，避免了直接求导函数为零这样的非线性方程的困难。</p>
<p>不过，这两种方法也存在它们自身的问题。最速下降法过于贪心，容易走出锯齿路线，反而增加了迭代次数。而牛顿法则需要计算目标函数的
<span class="math inline">\(\boldsymbol{H}\)</span>
矩阵，这在问题规模较大时非常困难，我们通常倾向于避免 <span
class="math inline">\(\boldsymbol{H}\)</span>
的计算。所以，接下来我们详细地介绍两类更加实用的方法： Gauss-Newton 和
Levenberg-Marquadt 。</p>
<h2 id="gauss-newton">3. Gauss-Newton</h2>
<p>Gauss Newton 是最优化算法里面最简单的方法之一。它的思想是将 <span
class="math inline">\(f(\boldsymbol{x})\)</span>
进行一阶的泰勒展开：<br />
<span class="math display">\[\label{局部近似}
f(\boldsymbol{x}+\Delta \boldsymbol{x}) \approx
f(\boldsymbol{x})+\boldsymbol{J}(\boldsymbol{x})\Delta\boldsymbol{x}
\]</span> 这里 <span
class="math inline">\(\boldsymbol{J}(\boldsymbol{x})\)</span> 是 <span
class="math inline">\(f(\boldsymbol{x})\)</span> 关于 <span
class="math inline">\(\boldsymbol{x}\)</span> 的导数，实际上是一个 <span
class="math inline">\(m\times m\)</span>
的矩阵，也是一个雅可比矩阵。</p>
<div class="note danger"><p>这里是对 <span class="math inline">\(f(\boldsymbol{x})\)</span> 在
<span class="math inline">\(\boldsymbol{x}\)</span>
处进行泰勒展开，而不是对目标函数进行泰勒展开，需要和 <a
href="#梯度法">梯度法</a> 中进行区分对比！</p>
</div>
<p>根据前面的思想，我们当前的目标是为了寻找下降矢量 <span
class="math inline">\(\Delta\boldsymbol{x}\)</span>，使 <span
class="math inline">\(\|f(\boldsymbol{x}+\Delta\boldsymbol{x})\|_{2}^{2}\)</span>
达到最小。即<br />
<span class="math display">\[
\Delta \boldsymbol{x}^{*}=arg\  \underset{\Delta \boldsymbol{x}}{min}
\frac{1}{2}\|f(\boldsymbol{x})+\boldsymbol{J}(\boldsymbol{x})\Delta\boldsymbol{x}\|_{2}^{2}
\]</span> 将目标函数展开化简得： <span class="math display">\[
\begin{equation*}
\begin{aligned}
\frac{1}{2}\|f(\boldsymbol{x})+\boldsymbol{J}(\boldsymbol{x})\Delta\boldsymbol{x}\|_{2}^{2}&amp;=\frac{1}{2}(f(\boldsymbol{x})+\boldsymbol{J}(\boldsymbol{x})\Delta\boldsymbol{x})^T(f(\boldsymbol{x})+\boldsymbol{J}(\boldsymbol{x})\Delta\boldsymbol{x})
\\
&amp;=\frac{1}{2}(\|f(\boldsymbol{x})\|_{2}^{2} +
2f(\boldsymbol{x})^T\boldsymbol{J}(\boldsymbol{x}+\Delta\boldsymbol{x}^T
\boldsymbol{J}(\boldsymbol{x})^T\boldsymbol{J}(x)^T\Delta
\boldsymbol{x}))
\end{aligned}
\end{equation*}
\]</span></p>
<p>求上述目标函数对 <span class="math inline">\(\Delta
\boldsymbol{x}\)</span> 的导数，并令其为 0： <span
class="math display">\[\nonumber
2\boldsymbol{J}(\boldsymbol{x})^T \boldsymbol{J}(\boldsymbol{x})\Delta
\boldsymbol{x}+2\boldsymbol{J}(\boldsymbol{x})^T f(\boldsymbol{x})=0
\]</span></p>
<p>可以得到： <span class="math display">\[
\boldsymbol{J}(\boldsymbol{x})^T \boldsymbol{J}(\boldsymbol{x})\Delta
\boldsymbol{x}=-\boldsymbol{J}(\boldsymbol{x})^T f(\boldsymbol{x})
\]</span></p>
<p>注意，我们要求解的变量是 <span class="math inline">\(\Delta
\boldsymbol{x}\)</span>，因此这是一个线性方程组，我们称它为<strong>增量方程</strong>，也可以称为<strong>高斯牛顿方程</strong>
(Gauss Newton equations) 或者<strong>正规方程</strong> (Normal
equations)。我们把左边的系数定义为 <span
class="math inline">\(\boldsymbol{H}\)</span>，右边定义为 <span
class="math inline">\(\boldsymbol{g}\)</span>，那么上式变为：<br />
<span class="math display">\[
\boldsymbol{H}\Delta \boldsymbol{x} = \boldsymbol{g}
\]</span></p>
<p>Gauss-Newton 的步骤可以写为：</p>
<ol type="1">
<li>给定初值 <span
class="math inline">\(\boldsymbol{x}_0\)</span>；<br />
</li>
<li>对于第 <span class="math inline">\(k\)</span>
次迭代，求出当前的雅可比矩阵 <span
class="math inline">\(\boldsymbol{J}(\boldsymbol{x}_k)\)</span>
和误差<span class="math inline">\(f(\boldsymbol{x}_k)\)</span>；<br />
</li>
<li>求解增量方程： <span class="math inline">\(\boldsymbol{H}\Delta
\boldsymbol{x}_k = \boldsymbol{g}\)</span> ；<br />
</li>
<li>如果 <span class="math inline">\(\Delta \boldsymbol{x}_k\)</span>
足够小，则停止；否则，令 <span
class="math inline">\(\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\Delta
\boldsymbol{x}_k\)</span> ，返回 2。</li>
</ol>
<p><strong>求解增量方程是整个优化问题的核心所在</strong>。</p>
<h3 id="小结-1">3.1 小结</h3>
<p>和 二阶梯度法（牛顿法）<span
class="math inline">\(\eqref{二阶梯度法}\)</span>
的增量解进行对比，可以发现 Gauss-Newton 中用 <span
class="math inline">\(\boldsymbol{J}^{T}\boldsymbol{J}\)</span>
作为牛顿法中二阶 Hessian 矩阵的近似，从而省略了计算 <span
class="math inline">\(\boldsymbol{H}\)</span> 的过程。</p>
<p>Gauss-Newton 的核心在于求解增量方程，但它要求 <span
class="math inline">\(\boldsymbol{H}\)</span>
是可逆且正定的，但实际中计算的 <span
class="math inline">\(\boldsymbol{H}=\boldsymbol{J}^{T}\boldsymbol{J}\)</span>
通常只是半正定的。因此，在使用 Gauss-Newton 的时候可能会出现 <span
class="math inline">\(\boldsymbol{H}\)</span>
是奇异或者病态的情况，导致算法不收敛。更严重的是，就算我们假设 <span
class="math inline">\(\boldsymbol{H}\)</span>
非奇异也非病态，如果我们求出来的步长 <span class="math inline">\(\Delta
\boldsymbol{x}\)</span> 太大，也会导致我们采用的局部近似 <span
class="math inline">\(\eqref{局部近似}\)</span>
不够准确，这样一来我们甚至都无法保证它的迭代收敛，哪怕是让目标函数变得更大都是有可能的。</p>
<p>尽管 Gauss-Newton
有这些缺点，但是它依然值得我们去学习，因为在非线性优化里，相当多的算法都可以归结为
Gauss-Newton 的变种。这些算法都借助了 Gauss-Newton
法的思想并且通过自己的改进修正 Gauss-Newton 法的缺点。例如一些线搜索方法
(line search method)，这类改进就是加入了一个标量 <span
class="math inline">\(\alpha\)</span>，在确定了 <span
class="math inline">\(\Delta \boldsymbol{x}\)</span> 进一步找到 <span
class="math inline">\(\alpha\)</span> 使得 <span
class="math inline">\(\|f(\boldsymbol{x}+\alpha \Delta
\boldsymbol{x})\|_{2}^{2}\)</span> 达到最小，而不是像 Gauss-Newton
法那样简单地令 <span class="math inline">\(α = 1\)</span>。</p>
<p>Levenberg-Marquadt
方法在一定程度上修正了这些问题，被称之为阻尼牛顿法(Damped Newton
Method)，一般认为它比高斯牛顿更为鲁棒。尽管它的收敛速度可能会比高斯牛顿更慢，但是在
SLAM 里面却被大量应用。</p>
<h2 id="levenberg-marquadt">4. Levenberg-Marquadt</h2>
<p>前文提到当 <span class="math inline">\(\Delta \boldsymbol{x}\)</span>
太大时，Gauss-Newton 方法中采用的近似二阶泰勒展开 <span
class="math inline">\(\eqref{局部近似}\)</span>
存在不够准确的问题，很自然的想到对 <span class="math inline">\(\Delta
\boldsymbol{x}\)</span> 增加一个信赖区域 (Trust Region)，不能让 <span
class="math inline">\(\Delta \boldsymbol{x}\)</span>
因太大而使得近似不够准却。这种添加信赖区域的方法在非线性优化中被称为
<strong>信赖区域方法 (Trust Region Method)</strong>
。只有在规定的信赖区域中的 <span class="math inline">\(\Delta
\boldsymbol{x}\)</span> 才认为近似是有效的。<br />
那么如何确定这个信赖区域的范围呢？一个比较好的方法是根据我们的近似模型跟实际函数之间的差异来确定这个范围：如果差异小，我们就让范围尽可能大；如果差异大，我们就缩小这个近似范围。因此，考虑使用下式来判断泰勒近似是否够好。
<span class="math display">\[
\rho=\frac{f(\boldsymbol{x+\Delta
\boldsymbol{x}})-f(\boldsymbol{x})}{\boldsymbol{J}(\boldsymbol{x})\Delta
\boldsymbol{x}}=\frac{实际函数下降值}{近似模型下降值}
\]</span> 显然，当 <span class="math inline">\(\rho \rightarrow
1\)</span> 时，近似效果最好；<br />
当 <span class="math inline">\(\rho \ll 1\)</span>
时，说明实际下降值远小于近似下降值，我们需要缩小近似范围，即减小 <span
class="math inline">\(\Delta \boldsymbol{x}\)</span> ；<br />
当 <span class="math inline">\(\rho \gg 1\)</span>
时，说明实际下降值远大于近似下降值，我们需要增大近似范围，即增大 <span
class="math inline">\(\Delta \boldsymbol{x}\)</span> 。</p>
<p>依此，我们可以改进 Gauss-Newton 非线性优化的框架：</p>
<ol type="1">
<li>给定初始值 <span
class="math inline">\(\boldsymbol{x}_0\)</span>，以及初始优化半径 <span
class="math inline">\(\mu\)</span>；</li>
<li>对于第 <span class="math inline">\(k\)</span> 次迭代，求解：<span
class="math display">\[\label{L-M} \underset{\Delta
\boldsymbol{x}_k}{min}
\frac{1}{2}\|f(\boldsymbol{x}_k)+\boldsymbol{J}(\boldsymbol{x}_k)\Delta
\boldsymbol{x}_k\|_{2}^{2},\ s.t.\|\boldsymbol{D}\Delta
\boldsymbol{x}_k\|^{2}\le \mu\]</span> 这里 <span
class="math inline">\(\mu\)</span> 是信赖区域的半径，<span
class="math inline">\(\boldsymbol{D}\)</span> 是一个调整矩阵</li>
<li>计算 <span class="math inline">\(\rho\)</span>；</li>
<li>如果 <span class="math inline">\(\rho \gt \frac{3}{4}\)</span>，则
<span class="math inline">\(\mu = 2\mu\)</span>；如果 <span
class="math inline">\(\rho \lt \frac{1}{4}\)</span>，则 <span
class="math inline">\(\mu = 0.5\mu\)</span>；否则，<span
class="math inline">\(\mu\)</span>
保持不变。这里的阈值和扩大倍数都是经验值，可视情况调整；</li>
<li>如果 <span class="math inline">\(\rho\)</span>
大于某阈值，认为近似可行。令 <span
class="math inline">\(\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\Delta
\boldsymbol{x}_k\)</span>；</li>
<li>判断算法是否收敛。如果不收敛则返回2，否则结束。</li>
</ol>
<p>关于 <span class="math inline">\(\eqref{L-M}\)</span> 中 <span
class="math inline">\(\boldsymbol{D}\)</span> 的说明：<br />
当 <span class="math inline">\(\boldsymbol{D}=\boldsymbol{I}\)</span>
时，这里的约束条件可看作是将 <span class="math inline">\(\Delta
\boldsymbol{x}\)</span> 约束在一个半径为 <span
class="math inline">\(\mu\)</span> 的球内；当 <span
class="math inline">\(\boldsymbol{D} \ne \boldsymbol{I}\)</span>
时，可以认为这是一个椭球。 在 L-M 算法中，取 <span
class="math inline">\(\boldsymbol{D}\)</span> 为非负对角矩阵（由 <span
class="math inline">\(\boldsymbol{J}^{T}\boldsymbol{J}\)</span>
的对角元素平方根构成），使得在梯度小的维度上约束范围更大一些。</p>
<p>根据<span class="math inline">\(\eqref{L-M}\)</span> 求解增量，
拉格朗日法： <span class="math display">\[
\nonumber
L=\frac{1}{2}\|f(\boldsymbol{x}_k)+\boldsymbol{J}(\boldsymbol{x}_k)\Delta
\boldsymbol{x}_k\|_{2}^{2}+\frac{\lambda}{2}\|\boldsymbol{D}\Delta\boldsymbol{x}_k\|_{2}^{2},\lambda
\gt 0
\]</span> 令偏导为0，可得增量方程： <span class="math display">\[
\frac{\partial L}{\partial \Delta\boldsymbol{x}_k}=\boldsymbol{0}
\Longrightarrow (\boldsymbol{H}+\lambda
\boldsymbol{D}^{T}\boldsymbol{D})\Delta \boldsymbol{x}_k=\boldsymbol{g}
\]</span></p>
<p>从结果来看，当 <span class="math inline">\(\lambda\)</span>
较小时，<span class="math inline">\(\boldsymbol{H}\)</span>
占主导地位，说明二次近似模型效果在该范围内是比较好的，此时 L-M 法接近于
G-N 法；当 <span class="math inline">\(\lambda\)</span> 较大时，考虑
<span class="math inline">\(\boldsymbol{D}=\boldsymbol{I}\)</span>
的简化形式，此时 <span class="math inline">\(\lambda \boldsymbol{D}^T
\boldsymbol{D}=\lambda \boldsymbol{I}\)</span>
占主导地位，说明二次近似的不够好，此时 L-M 法更接近于
一阶梯度下降法（最速下降法）。</p>
<p>L-M
的求解方式，可在一定程度上避免线性方程组的系数矩阵的非奇异和病态问题，提供更稳定更准确的增量
<span class="math inline">\(\Delta \boldsymbol{x}\)</span>。</p>
<p>总而言之，非线性优化问题的框架，分为 Line Search 和 Trust Region
两类。<br />
Line Search 先固定搜索方向，然后在该方向寻找步长，以最速下降法和
Gauss-Newton 法为代表。而 TrustRegion
则先固定搜索区域，再考虑找该区域内的最优点。此类方法以 L-M
为代表。实际问题中，我们通常选择 G-N 或 L-M 之一作为梯度下降策略。</p>
<h2 id="参考资料">5. 参考资料</h2>
<p><strong>[1]</strong> 视觉 SLAM 十四讲 —— 高翔</p>
]]></content>
      <categories>
        <category>最优化</category>
        <category>非线性最小二乘</category>
      </categories>
      <tags>
        <tag>非线性最小二乘</tag>
      </tags>
  </entry>
</search>
